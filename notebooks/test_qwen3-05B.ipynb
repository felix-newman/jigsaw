{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe12a699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5855d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text (Thinking): <|im_start|>user\n",
      "Describe the content of the r/aww subreddit in 2-3 sentences. Be precise and concise.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "Text (No Thinking): <|im_start|>user\n",
      "Describe the content of the r/aww subreddit in 2-3 sentences. Be precise and concise.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "\n",
      "thinking content: <think>\n",
      "Okay, the user wants me to describe the content of the r/aww subreddit in 2-3 sentences. First, I need to recall what the r/aww subreddit is known for. From what I remember, it's a subreddit focused on gaming, especially the latest in-game content. It's a community where players share their experiences and updates with the game.\n",
      "\n",
      "Wait, but I should make sure about the specifics. Some sources mention that it's a place for discussing new game updates, in-game events, and community discussions. Also, it's a hub for players to exchange information and get updates. \n",
      "\n",
      "I need to be precise and concise. Let me structure it: start with the main focus, mention the community aspect, and include the specific topics like updates and discussions. That should cover it without being too vague. Let me check if I'm missing anything. Oh, maybe the r/aww subreddit is a popular place for gamers, so including that as a community is good. Alright, that should do it.\n",
      "</think>\n",
      "content: The r/aww subreddit is a gaming community where players share in-game updates, events, and discussions about new game content, offering a space for exchange and engagement with fellow gamers. It emphasizes collaboration and creativity, fostering a dynamic environment for exploring game advancements.\n"
     ]
    }
   ],
   "source": [
    "# prepare the model input\n",
    "prompt = \"Describe the content of the r/aww subreddit in 2-3 sentences. Be precise and concise.\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True,  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "print(f\"Text (Thinking): {text}\")\n",
    "text_no_thinking = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True, enable_thinking=False\n",
    ")\n",
    "print(f\"Text (No Thinking): {text_no_thinking}\")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=32768)\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]) :].tolist()\n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\n",
    "    \"\\n\"\n",
    ")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616a569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
